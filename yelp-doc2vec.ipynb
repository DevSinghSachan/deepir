{
 "metadata": {
  "name": "",
  "signature": "sha256:bc981da59eff75992506316a3062ba91f205cbd7716629ae6dce9bea79322af4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "import sys\n",
      "import numpy as np\n",
      "from copy import deepcopy\n",
      "from gensim.models.doc2vec import *\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "alteos = re.compile(r'( [!\\?] )')\n",
      "\n",
      "def YelpLabeledSentence( stars = [1,2,3,4,5], prefix=\"train\" ):\n",
      "    for nstar in stars:\n",
      "        i = 0\n",
      "        for line in open(\"data/yelp%s%dstar.txt\"%(prefix,nstar)):\n",
      "            line = alteos.sub(r' \\1 . ', line).rstrip(\"( \\. )*\\n\")\n",
      "            lab = \"%s-%d-%d\" % (prefix, nstar, i)\n",
      "            rev = [s.split() for s in line.split(\" . \")]\n",
      "            i += 1\n",
      "            for s in rev:\n",
      "                yield LabeledSentence(s, [lab])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainsent = list(YelpLabeledSentence())\n",
      "testsent = list(YelpLabeledSentence(prefix=\"test\"))\n",
      "allsent = trainsent + testsent\n",
      "print((allsent[0].words, allsent[0].labels))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(['u', 'can', 'go', 'there', 'n', 'check', 'car', 'out'], ['train-1-0'])\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = Doc2Vec(workers=4,size=100,window=8, dm=0)\n",
      "%time model.build_vocab(allsent)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 32.2 s, sys: 771 ms, total: 32.9 s\n",
        "Wall time: 32.9 s\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.min_alpha = model.alpha\n",
      "for epoch in range(10):\n",
      "    print(epoch)\n",
      "    np.random.shuffle(trainsent)\n",
      "    model.train(trainsent)\n",
      "    model.alpha *= 0.9\n",
      "    model.min_alpha = model.alpha"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def nearby(word):\n",
      "    print(word)\n",
      "    for (w,v) in model.most_similar([word]):\n",
      "        print(w, end=\" \")\n",
      "    print(\"\\n\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nearby(\"food\")\n",
      "nearby(\"service\")\n",
      "nearby(\"value\")\n",
      "nearby(\"atmosphere\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "food\n",
        "train-4-44025"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " train-4-67778 train-2-7078 train-2-8807 train-3-4902 clara train-5-54314 test-5-2796 train-4-1832 test-2-955 \n",
        "\n",
        "service\n",
        "train-5-1449 train-4-62292 train-5-2056 train-4-78785 train-4-56939 train-4-39009 train-3-32836 train-5-22771 train-5-35162 train-3-19949 \n",
        "\n",
        "value\n",
        "test-1-1036"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " train-5-13747 tactful hasbrown train-4-7985 train-1-12144 train-1-15003 train-1-9276 train-2-17756 ringlet \n",
        "\n",
        "atmosphere\n",
        "test-5-6279"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " sot dissonance reunit test-1-391 immediat mariee test-5-3411 fastfood attractive \n",
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.train_words=False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.min_alpha = model.alpha = 0.025\n",
      "for epoch in range(10):\n",
      "    print(epoch)\n",
      "    np.random.shuffle(testsent)\n",
      "    model.train(testsent)\n",
      "    model.alpha *= 0.9\n",
      "    model.min_alpha = model.alpha"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = re.match(\"train-\\d-\\d+\", \"test-5-74939\")\n",
      "if i: print(\"yes\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "itrainneg = [model.vocab[w].index for w in model.vocab if re.match(\"train-[1|2]-\\d+\", w) ]\n",
      "itrainpos = [model.vocab[w].index for w in model.vocab if re.match(\"train-5-\\d+\", w) ]\n",
      "itestneg = [model.vocab[w].index for w in model.vocab if re.match(\"test-[1|2]-\\d+\", w) ]\n",
      "itestpos = [model.vocab[w].index for w in model.vocab if re.match(\"test-5-\\d+\", w) ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xtrain = np.vstack( ( model.syn0[itrainneg,:], model.syn0[itrainpos,:]) )\n",
      "ytrain = np.repeat( [0,1], [len(itrainneg),len(itrainpos)], axis=0)\n",
      "xtest = np.vstack( ( model.syn0[itestneg,:], model.syn0[itestpos,:]) )\n",
      "ytest = np.repeat( [0,1], [len(itestneg),len(itestpos)], axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## try logistic regression\n",
      "from sklearn import linear_model\n",
      "lmreg = linear_model.LogisticRegression()\n",
      "lmreg.fit(xtrain, ytrain)\n",
      "yhatlm = lmreg.predict(xtest)\n",
      "print(\"MCR = %.3f\"%np.mean(yhatlm!=ytest))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MCR = 0.073\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## or a random forest\n",
      "from sklearn import ensemble\n",
      "rfreg = ensemble.RandomForestClassifier(100,n_jobs=4)\n",
      "rfreg.fit(xtrain, ytrain)\n",
      "yhatrf = rfreg.predict(xtest)\n",
      "print(\"MCR = %.3f\"%np.mean(yhatrf!=ytest))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MCR = 0.117\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So neither do as well as w2v inversion, which itself doesn't perform as well as a linear model (but it is close)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### try 'sentiment' labels"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def YelpNNPSentence( stars = [1,2,3,4,5], prefix=\"train\" ):\n",
      "    for nstar in stars:\n",
      "        i = 0\n",
      "        for line in open(\"data/yelp%s%dstar.txt\"%(prefix,nstar)):\n",
      "            line = alteos.sub(r' \\1 . ', line).rstrip(\"( \\. )*\\n\")\n",
      "            if nstar < 3:\n",
      "                lab = \"negativesentiment\"\n",
      "            elif nstar > 4:\n",
      "                lab = \"positivesentiment\"\n",
      "            else:\n",
      "                lab = \"neutralsentiment\"\n",
      "            rev = [s.split() for s in line.split(\" . \")]\n",
      "            i += 1\n",
      "            for s in rev:\n",
      "                yield LabeledSentence(s, [lab])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nnpsent = list(YelpNNPSentence())\n",
      "print((nnpsent[0].words, nnpsent[0].labels))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(['u', 'can', 'go', 'there', 'n', 'check', 'car', 'out'], ['negativesentiment'])\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = Doc2Vec(workers=4,size=100,window=8)\n",
      "%time model.build_vocab(nnpsent)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 15.7 s, sys: 65.7 ms, total: 15.7 s\n",
        "Wall time: 15.8 s\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.min_alpha = model.alpha\n",
      "for epoch in range(10):\n",
      "    print(epoch)\n",
      "    np.random.shuffle(nnpsent)\n",
      "    model.train(nnpsent)\n",
      "    model.alpha *= 0.9\n",
      "    model.min_alpha = model.alpha"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nearby(\"food\")\n",
      "nearby(\"service\")\n",
      "nearby(\"value\")\n",
      "nearby(\"atmosphere\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "food\n",
        "cuisine foodish meal fare cookery pizza cusine ingredient foodstuff stuff \n",
        "\n",
        "service\n",
        "sevice serivce waitstaff execution value qualtiy staff relation svc hygiene \n",
        "\n",
        "value\n",
        "qualtiy service equalizer sevice overall samaritan hotmail sightline instill mulder \n",
        "\n",
        "atmosphere\n",
        "ambience"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ambiance environment vibe atmostphere atmoshpere decor atmoshere atomsphere sett \n",
        "\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def nearfar(near=[],far=[]):\n",
      "    for w in near:\n",
      "        print(\"+%s\"%w, end=\" \")\n",
      "    for w in far:\n",
      "        print(\"-%s\"%w, end=\" \")\n",
      "    print(\"\")\n",
      "    for (w,v) in model.most_similar(near,far):\n",
      "        print(w, end=\" \")\n",
      "    print(\"\\n\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nearfar([\"positivesentiment\"],[\"negativesentiment\",\"neutralsentiment\"])\n",
      "nearfar([\"negativesentiment\"],[\"positivesentiment\",\"neutralsentiment\"])\n",
      "nearfar([\"positivesentiment\"],[\"negativesentiment\"])\n",
      "nearfar([\"negativesentiment\"],[\"positivesentiment\"])\n",
      "nearfar([\"positivesentiment\"],[\"neutralsentiment\"])\n",
      "nearfar([\"negativesentiment\"],[\"neutralsentiment\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "+positivesentiment -negativesentiment -neutralsentiment \n",
        "michael preciou germaine northwest creamy frothy mariquita justifiab bride affair \n",
        "\n",
        "+negativesentiment -positivesentiment -neutralsentiment \n",
        "insecurity indignant helene unflavorful mofongo unforeseen rada tragedie overbrewe asst \n",
        "\n",
        "+positivesentiment -negativesentiment \n",
        "rendezvou frock eegee peso michael w00t underappreciate }, earne !] \n",
        "\n",
        "+negativesentiment -positivesentiment \n",
        "correct indignant smackdown improper shiu underflavore logistic releno reall braciole \n",
        "\n",
        "+positivesentiment -neutralsentiment \n",
        "heartbreak gondolier peso chamber hei acura saab bebe teacher shauna \n",
        "\n",
        "+negativesentiment -neutralsentiment \n",
        "rotten snowman lib adolescent governor mea icu overbrewe compressor improper \n",
        "\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def YelpReviews( stars = [1,2,3,4,5], prefix=\"train\" ):\n",
      "    for nstar in stars:\n",
      "        for line in open(\"data/yelp%s%dstar.txt\"%(prefix,nstar)):\n",
      "            line = alteos.sub(r' \\1 . ', line).rstrip(\"( \\. )*\\n\")\n",
      "            yield [s.split() for s in line.split(\" . \")]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testrev = {}\n",
      "testrev['neg'] = list(YelpReviews([1,2],\"test\"))\n",
      "testrev['pos'] = list(YelpReviews([5],\"test\"))\n",
      "\n",
      "reviews = {}\n",
      "reviews['neg'] = list(YelpReviews([1,2]))\n",
      "reviews['pos'] = list(YelpReviews([5]))\n",
      "nbad = len(reviews['neg'])\n",
      "ngood = len(reviews['pos'])\n",
      "prior = ngood/(nbad + ngood)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getscore(rev):\n",
      "    sentences =  [(i,s) for i,r in enumerate(rev) for s in r]\n",
      "    labsentneg = [LabeledSentence(s,\"negativesentiment\") for i,s in sentences]\n",
      "    labsentpos = [LabeledSentence(s,\"positivesentiment\") for i,s in sentences]\n",
      "    eta = np.column_stack( \n",
      "                    ( model.score(labsentneg),\n",
      "                      model.score(labsentpos) ) )\n",
      "    probs = np.exp( eta - eta.max(axis=1)[:,np.newaxis] )\n",
      "    #probs *= np.array([(1-prior),prior])\n",
      "    probs = probs/probs.sum(axis=1)[:,np.newaxis]\n",
      "    agg = np.column_stack( \n",
      "                    ( np.bincount([i for i,s in sentences], probs[:,0]),\n",
      "                      np.bincount([i for i,s in sentences], probs[:,1]) ) )\n",
      "    probpos = agg[:,1]/np.bincount([i for i,s in sentences])\n",
      "    return(probpos)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = {}\n",
      "scores['neg'] = getscore(testrev['neg'])\n",
      "scores['pos'] = getscore(testrev['pos'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "RuntimeError",
       "evalue": "we have only implemented score for hs and sg",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-25-4e2a3cc9aa0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestrev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestrev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-24-295c1403e156>\u001b[0m in \u001b[0;36mgetscore\u001b[0;34m(rev)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlabsentpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mLabeledSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"positivesentiment\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     eta = np.column_stack( \n\u001b[0;32m----> 6\u001b[0;31m                     ( model.score(labsentneg),\n\u001b[0m\u001b[1;32m      7\u001b[0m                       model.score(labsentpos) ) )\n\u001b[1;32m      8\u001b[0m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/mtaddy/packages/gensim/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, sentences, total_sentences, chunksize)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"we have only implemented score for hs and sg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_report\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mRuntimeError\u001b[0m: we have only implemented score for hs and sg"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}